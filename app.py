import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import os

# 1. ƒê·ªãnh nghƒ©a l·∫°i c·∫•u tr√∫c Model (Ph·∫£i gi·ªëng h·ªát file code.py c·ªßa b·∫°n)
class LeNetClassifer(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)
        self.avgpool1 = nn.AvgPool2d(kernel_size=2)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        self.avgpool2 = nn.AvgPool2d(kernel_size=2)
        self.flatten = nn.Flatten()
        self.fc_1 = nn.Linear(16 * 5 * 5, 120)
        self.fc_2 = nn.Linear(120, 84)
        self.fc_3 = nn.Linear(84, num_classes)

    def forward(self, x):
        x = F.relu(self.avgpool1(self.conv1(x)))
        x = F.relu(self.avgpool2(self.conv2(x)))
        x = self.flatten(x)
        x = F.relu(self.fc_1(x))
        x = F.relu(self.fc_2(x))
        x = self.fc_3(x)
        return x

# 2. H√†m load model ƒë√£ train
@st.cache_resource
def load_model():
    model = LeNetClassifer(num_classes=10)
    # ƒê∆∞·ªùng d·∫´n n√†y tr·ªè v√†o th∆∞ m·ª•c model/ file lenet_model.pt c·ªßa b·∫°n
    model_path = 'model/lenet_model.pt'
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
        model.eval()
        return model
    else:
        st.error(f"Kh√¥ng t√¨m th·∫•y file model t·∫°i {model_path}")
        return None

model = load_model()

# 3. Giao di·ªán Streamlit
st.set_page_config(page_title="MNIST Digit Predictor", layout="centered")
st.title("üî¢ D·ª± ƒëo√°n ch·ªØ s·ªë vi·∫øt tay LeNet-5")
st.write("D·ª± √°n CNN 2026 - Nh·∫≠n di·ªán ch·ªØ s·ªë t·ª´ b·ªô d·ªØ li·ªáu MNIST")

uploaded_file = st.file_uploader("Upload ·∫£nh ch·ªØ s·ªë (n·ªÅn ƒëen ch·ªØ tr·∫Øng s·∫Ω ch√≠nh x√°c h∆°n)...", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('L') # Chuy·ªÉn v·ªÅ ·∫£nh x√°m (Grayscale)
    st.image(image, caption='·∫¢nh ƒë√£ upload', width=200)
    
    # 4. Ti·ªÅn x·ª≠ l√Ω ·∫£nh (D√πng ƒë√∫ng th√¥ng s·ªë mean/std b·∫°n ƒë√£ d√πng l√∫c train)
    mean = 0.1307
    std = 0.3081
    
    transform = transforms.Compose([
        transforms.Resize((28, 28)),
        transforms.ToTensor(),
        transforms.Normalize((mean,), (std,))
    ])
    
    img_tensor = transform(image).unsqueeze(0) # Th√™m batch dimension

    # 5. D·ª± ƒëo√°n
    if st.button('Ki·ªÉm tra k·∫øt qu·∫£'):
        if model is not None:
            with torch.no_grad():
                output = model(img_tensor)
                # T√≠nh x√°c su·∫•t b·∫±ng Softmax
                probabilities = F.softmax(output, dim=1)
                prob, predicted = torch.max(probabilities, 1)
                
                st.success(f"### K·∫øt qu·∫£ d·ª± ƒëo√°n: {predicted.item()}")
                st.write(f"ƒê·ªô tin c·∫≠y: {prob.item()*100:.2f}%")
